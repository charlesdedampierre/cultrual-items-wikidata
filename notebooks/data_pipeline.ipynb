{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2dac759-d690-497e-93fc-b67ed63fb24c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import typing as t\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9526d8f8-e8fa-417b-993e-c7a7aba546ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 37/37 [02:29<00:00,  4.03s/it]\n"
     ]
    }
   ],
   "source": [
    "#input_path = 'raw_data/raw_metadata/work_of_art/batch_1.json'\n",
    "\n",
    "\n",
    "input_paths = glob.glob('raw_data/raw_metadata/work_of_art/*')\n",
    "\n",
    "full_list = []\n",
    "for input_path in tqdm(input_paths):\n",
    "\n",
    "    with open(input_path) as f:\n",
    "        data = f.read()\n",
    "\n",
    "    dict_data = json.loads(data)\n",
    "    #dict_data = dict_data[:10000]\n",
    "    dict_data = [x for x in dict_data if x != None]\n",
    "    full_list.append(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13775ef4-5567-489d-929a-8642581113d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flattened_list = [item for sublist in full_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d662fb55-be05-4c82-95cd-5840d5465245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_selection_json(dict_data: t.List[t.List[t.Dict]]):\n",
    "\n",
    "    # First clean and keep needed data\n",
    "    final_list = []\n",
    "    for element in tqdm(dict_data):\n",
    "        \n",
    "        try:\n",
    "\n",
    "            final_ind_list = []\n",
    "\n",
    "            for data in element:\n",
    "\n",
    "                new_dict = dict()\n",
    "                for key in data.keys():\n",
    "                    new_dict[key] = data[key]['value']\n",
    "\n",
    "                transformed_data = {}\n",
    "                for key in list(new_dict.keys()):\n",
    "                    if 'Label' in key:\n",
    "                        non_label_key = key.split('Label')[0]\n",
    "                        transformed_data[non_label_key] = {'wiki_id':new_dict[non_label_key], 'label':new_dict[key]}\n",
    "\n",
    "                    # Handle Non Labeled keys\n",
    "                    elif 'inception' in key:\n",
    "                        transformed_data[key] = new_dict[key]\n",
    "\n",
    "                final_ind_list.append(transformed_data)\n",
    "                \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        final_list.append(final_ind_list)\n",
    "        \n",
    "    return final_list\n",
    "\n",
    "def data_cleaning_json(final_list: t.List[t.List[t.Dict]]):\n",
    "\n",
    "    # Simplify and get rid of duplicates\n",
    "    end_of_the_game_list = []\n",
    "    for element in tqdm(final_list):\n",
    "\n",
    "        # Instantiate keys\n",
    "        keys = []\n",
    "        for x in element:\n",
    "            for key in x.keys():\n",
    "                keys.append(key)\n",
    "        keys = list(set(keys))\n",
    "\n",
    "        clean_list = dict()\n",
    "        for key in keys:\n",
    "            clean_list[key] = list()\n",
    "\n",
    "        for dict_element in element:\n",
    "            for key in list(dict_element.keys()):\n",
    "                clean_list[key].append(dict_element[key])\n",
    "\n",
    "        # Drop Duplicates\n",
    "        new_clean_list = dict()\n",
    "        for key in clean_list.keys():\n",
    "            d = clean_list[key]\n",
    "            \n",
    "            if key == 'inception':\n",
    "                new_d = list(pd.DataFrame(d).drop_duplicates()[0])\n",
    "            else:\n",
    "                new_d = pd.DataFrame(d).drop_duplicates().to_dict(orient = 'records')\n",
    "            new_clean_list[key] = new_d\n",
    "        \n",
    "        # subject is always unique, so we take the first element of the list\n",
    "        new_clean_list['subject'] = new_clean_list['subject'][0] \n",
    "        end_of_the_game_list.append(new_clean_list)\n",
    "\n",
    "    return end_of_the_game_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "680c624b-19d6-4850-948a-1a5c05d9f386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_date(raw_date):\n",
    "    try:\n",
    "        if raw_date.startswith(\"-\"):\n",
    "            clean_date = int(raw_date[:5])\n",
    "        else:\n",
    "            clean_date = int(raw_date[:4])\n",
    "\n",
    "    except:\n",
    "        clean_date = None\n",
    "    return clean_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "131485a0-513a-4e9b-9e2c-6b60d3c1d5a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class WikidataEntity(BaseModel):\n",
    "    wiki_id: str\n",
    "    label: str\n",
    "    \n",
    "    @property\n",
    "    def get_id(self) -> str:\n",
    "        return self.wiki_id.split(\"/\")[-1]\n",
    "\n",
    "class ComplexityObject(BaseModel):\n",
    "    subject: WikidataEntity\n",
    "    instance: Optional[List[WikidataEntity]]\n",
    "    subclass: Optional[List[WikidataEntity]]\n",
    "    inception: Optional[List[str]]\n",
    "    time_period: Optional[List[WikidataEntity]]\n",
    "    culture: Optional[List[WikidataEntity]]\n",
    "    architecture_style: Optional[List[WikidataEntity]]\n",
    "    founded_by: Optional[List[WikidataEntity]]\n",
    "    creator: Optional[List[WikidataEntity]]\n",
    "    country: Optional[List[WikidataEntity]]\n",
    "    territory: Optional[List[WikidataEntity]]\n",
    "    genre: Optional[List[WikidataEntity]]\n",
    "    movement: Optional[List[WikidataEntity]]\n",
    "    \n",
    "    @property\n",
    "    def get_year(self) -> str:\n",
    "        return [clean_date(y) for y in self.inception]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebe902ef-9a5c-4a27-92b0-f7cf98210c90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 3629042/3629042 [02:03<00:00, 29290.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# Clean Json\n",
    "\n",
    "final_list = data_selection_json(flattened_list)\n",
    "#final_list = final_list[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "565cb788-f89d-44e3-845f-47dd6e7f3c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 3629042/3629042 [1:04:43<00:00, 934.56it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_list = data_cleaning_json(final_list)\n",
    "\n",
    "# Insert into objects\n",
    "final_obj = [ComplexityObject(**x) for x in final_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0403dd0-7dae-4ee4-b6de-4e194ad10e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from extraction.sys_utils import save_model\n",
    "save_model(final_obj, name=\"raw_data/work_of_art.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761ac18e-37d2-4ebb-9972-66e287ed3d3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### To Sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d1b6f57-18cf-4e0c-96f7-87bd8057064f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a618dc-b617-497f-ab44-0dcafb58f0b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take a long time for more than 1,000,000 data\n",
    "df_fil = [\n",
    "    {\"subject\":x.subject.get_id,\n",
    "        \"subjectLabel\": x.subject.label,\n",
    "        \"inception\": x.get_year if x.inception is not None else [],\n",
    "        \"instance\": [y.get_id for y in x.instance] if x.instance is not None else [],\n",
    "         \"subclass\": [y.get_id for y in x.instance] if x.subclass is not None else [],\n",
    "        \"creator\": [y.get_id for y in x.creator] if x.creator is not None else [],\n",
    "          \"time_period\": [y.get_id for y in x.time_period] if x.time_period is not None else [],\n",
    "          \"culture\": [y.get_id for y in x.culture] if x.culture is not None else [],\n",
    "          \"architecture_style\": [y.get_id for y in x.architecture_style] if x.architecture_style is not None else [],\n",
    "          \"founded_by\": [y.get_id for y in x.founded_by] if x.founded_by is not None else [],\n",
    "          \"country\": [y.get_id for y in x.country] if x.country is not None else [],\n",
    "          \"territory\": [y.get_id for y in x.territory] if x.territory is not None else [],\n",
    "          \"genre\": [y.get_id for y in x.genre] if x.genre is not None else [],\n",
    "          \"movement\": [y.get_id for y in x.movement] if x.movement is not None else [],\n",
    "        \n",
    "    }\n",
    "    for x in final_obj\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b760e-5553-4aa7-a6e9-d5ccd3e155cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7f9527b1-734d-4f20-b06e-e702348081bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Add only keys\n",
    "\n",
    "# connect to SQLite3 database\n",
    "conn = sqlite3.connect('works.db')\n",
    "\n",
    "# create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# get a list of all tables in the database\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "# drop each table in the database\n",
    "for table in tables:\n",
    "    cursor.execute(f\"DROP TABLE IF EXISTS {table[0]}\")\n",
    "\n",
    "# commit the changes and close the connection\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6f6a29ca-1b0e-4c65-a790-280996c22ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = [\n",
    " 'inception',\n",
    " 'instance',\n",
    " 'subclass',\n",
    " 'creator',\n",
    " 'time_period',\n",
    " 'culture',\n",
    " 'architecture_style',\n",
    " 'founded_by',\n",
    " 'country',\n",
    " 'territory',\n",
    " 'genre',\n",
    " 'movement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b4d7da-ee93-4666-8495-44c4b4c03288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "438eadea-a507-46c1-a57e-c4d447909d80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inception\n",
      "instance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████████▌                                                         | 2/12 [10:10<50:52, 305.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subclass\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████████████▎                                                   | 3/12 [13:34<39:27, 263.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███████████████████████                                              | 4/12 [23:52<52:43, 395.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_period\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████████████████▊                                        | 5/12 [27:09<38:06, 326.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "culture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████████████████████████████████▌                                  | 6/12 [29:48<27:05, 270.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture_style\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|████████████████████████████████████████▎                            | 7/12 [40:32<32:34, 390.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "founded_by\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████████████████████████████████                       | 8/12 [43:17<21:19, 319.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████████████████████████████▊                 | 9/12 [46:13<13:45, 275.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "territory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████████████████████████████▋           | 10/12 [57:30<13:17, 398.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genre\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|████████████████████████████████████████████████████████████▌     | 11/12 [1:01:25<05:48, 348.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 12/12 [1:04:27<00:00, 322.26s/it]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(cols):\n",
    "    print(col)\n",
    "    \n",
    "    if col == 'inception':\n",
    "        continue\n",
    "    \n",
    "    df_fil_label = [\n",
    "            {\"subject\":x.subject.get_id,\n",
    "            \"subjectLabel\": x.subject.label,\n",
    "            col: [y.get_id for y in getattr(x, col)] if getattr(x, col)is not None else [],\n",
    "\n",
    "\n",
    "        }\n",
    "        for x in final_obj\n",
    "    ]\n",
    "    \n",
    "    res = pd.DataFrame(df_fil_label)    \n",
    "    # only keep the subject with a proper name\n",
    "    res = res[~res['subjectLabel'].str.startswith('Q')]\n",
    "    res = res.explode(col)\n",
    "    res = res.dropna()\n",
    "    res = res[res[col].str.startswith('Q')]\n",
    "    res = res.drop_duplicates()\n",
    "    res.to_sql(f'subject_{col}', conn, if_exists = 'replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "265e3d86-3028-4d48-b0b9-962db167eeca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add inception\n",
    "col = 'inception'\n",
    "df_fil_label = [\n",
    "    {\"subject\":x.subject.get_id,\n",
    "    \"subjectLabel\": x.subject.label,\n",
    "    \"inception\": x.get_year if x.inception is not None else []\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "for x in final_obj\n",
    "]\n",
    "\n",
    "res = pd.DataFrame(df_fil_label)    \n",
    "# only keep the subject with a proper name\n",
    "res = res[~res['subjectLabel'].str.startswith('Q')]\n",
    "res = res.explode(col)\n",
    "res = res.dropna()\n",
    "res = res.drop_duplicates()\n",
    "\n",
    "res.to_sql(f'subject_{col}', conn, if_exists = 'replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6650808e-d7a5-4c79-8606-2ab861e4b080",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 12/12 [23:40<00:00, 118.37s/it]\n"
     ]
    }
   ],
   "source": [
    "all_attributes = ['subject',\n",
    "                  'creator', \n",
    "                 'instance',\n",
    "                  'subclass',\n",
    "                 'time_period',\n",
    "                 'culture',\n",
    "                 'architecture_style',\n",
    "                 'founded_by',\n",
    "                 'country',\n",
    "                 'territory',\n",
    "                 'genre',\n",
    "                 'movement']\n",
    "\n",
    "for attr_to_filter in tqdm(all_attributes):\n",
    "        \n",
    "    name = attr_to_filter + \"Label\"\n",
    "\n",
    "    final_obj_fil = [x for x in final_obj if getattr(x, attr_to_filter)]\n",
    "    \n",
    "    if attr_to_filter == 'subject':\n",
    "    \n",
    "        df_fil_label = [\n",
    "                {\n",
    "                    attr_to_filter: getattr(x, attr_to_filter).get_id,\n",
    "                     name: getattr(x, attr_to_filter).label\n",
    "\n",
    "\n",
    "                }\n",
    "                for x in final_obj_fil\n",
    "            ]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        df_fil_label = [\n",
    "            {\n",
    "                attr_to_filter: [y.get_id for y in getattr(x, attr_to_filter)] if getattr(x, attr_to_filter)is not None else [],\n",
    "                 name: [y.label for y in getattr(x, attr_to_filter)] if getattr(x, attr_to_filter) is not None else [],\n",
    "\n",
    "\n",
    "            }\n",
    "            for x in final_obj_fil\n",
    "        ]\n",
    "\n",
    "    # insert with the count of variables\n",
    "    df_fil_label = pd.DataFrame(df_fil_label)\n",
    "    df_fil_label = df_fil_label.explode([attr_to_filter, name])\n",
    "    df_fil_label = df_fil_label[df_fil_label[attr_to_filter].str.startswith('Q')]\n",
    "    df_fil_label = df_fil_label.groupby([attr_to_filter, name])[name].count().rename('count_all').reset_index()\n",
    "    df_fil_label = df_fil_label.sort_values('count_all', ascending=False)\n",
    "    \n",
    "    if attr_to_filter == 'subject':\n",
    "        df_fil_label = df_fil_label[~df_fil_label[name].str.startswith('Q')]\n",
    "        df_fil_label['origin'] = 'work_of_art_Q838948'\n",
    "    \n",
    "    #df_fil_label = df_fil_label.drop_duplicates().reset_index(drop=True)\n",
    "    df_fil_label.to_sql(name, conn, if_exists = 'replace', index=False)\n",
    "\n",
    "#conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
